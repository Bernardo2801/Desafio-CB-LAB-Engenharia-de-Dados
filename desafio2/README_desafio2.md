ğŸ‡§ğŸ‡·
# Desafio 2 â€“ Armazenamento de dados no Data Lake da CB LAB

## Objetivo

Armazenar, organizar e estruturar as respostas de 5 endpoints de API referentes Ã  rede de restaurantes, garantindo rastreabilidade, consistÃªncia histÃ³rica e escalabilidade para anÃ¡lises futuras.

---

## QuestÃµes solicitadas

### 1. Por que armazenar as respostas das APIs?

Armazenar as respostas das APIs garante:

- **Rastreabilidade e Auditoria:** Permite verificar inconsistÃªncias futuras e validar informaÃ§Ãµes.
- **Fonte ConfiÃ¡vel e HistÃ³rica:** APIs podem sofrer alteraÃ§Ãµes, quedas ou atualizaÃ§Ãµes. Ter os dados persistidos garante a integridade histÃ³rica.
- **AnÃ¡lises e Reprocessamento:** Possibilita novas anÃ¡lises ou geraÃ§Ã£o de relatÃ³rios sem reconsultar as APIs.
- **Evita Perda de Dados:** Garante persistÃªncia mesmo com eventuais falhas na fonte original.

---

### 2. Como armazenar os dados?

Foi adotada uma **estrutura particionada** para facilitar buscas, filtros, validaÃ§Ãµes e leitura eficiente por data e loja.

```
/data-lake/raw/cb_lab_api/
â””â”€â”€ [endpoint-name]/
    â””â”€â”€ year=2025/
        â””â”€â”€ month=07/
            â””â”€â”€ day=25/
                â””â”€â”€ storeId=001/
                    â””â”€â”€ response.json
```

#### Justificativa:

- OrganizaÃ§Ã£o clara por endpoint e data
- Facilita uso por ferramentas de Big Data como Hive, Spark ou Presto
- EscalÃ¡vel para milhares de arquivos
- Permite compressÃ£o e polÃ­ticas de retenÃ§Ã£o

---

### 3. MudanÃ§a no schema: `guestChecks.taxes` â†’ `guestChecks.taxation`

#### ImplicaÃ§Ãµes:

- Quebra de pipelines existentes que esperam o campo antigo;
- Erros em transformaÃ§Ãµes, parse de dados e dashboards;
- Necessidade de versionamento ou validaÃ§Ã£o de schema.

---

## Processo de Pensamento

### Etapas

1. Entendimento da necessidade: ingestÃ£o bruta para reprocessamentos e auditoria
2. CriaÃ§Ã£o de estrutura lÃ³gica por data e loja
3. PreocupaÃ§Ãµes com volume, schema e confiabilidade
4. OrganizaÃ§Ã£o de arquivos para fÃ¡cil consulta por ferramentas de anÃ¡lise

---

## PreocupaÃ§Ãµes

| Tipo                 | DescriÃ§Ã£o                                                        |
|----------------------|------------------------------------------------------------------|
| MudanÃ§as silenciosas | Podem quebrar pipelines â€” prever mÃºltiplos schemas               |
| Volume de dados      | Considerar compressÃ£o e ciclo de vida                            |
| ValidaÃ§Ã£o de schema  | Adiar para etapa posterior para evitar falhas imediatas          |

---

## ConsequÃªncias das DecisÃµes

| DecisÃ£o                         | ConsequÃªncia Positiva                   | PossÃ­vel Risco / MitigaÃ§Ã£o                        |
|-------------------------------  |-----------------------------------------|---------------------------------------------------|
| Armazenar JSONs brutos          | Preserva dados para reprocessamento     | CompressÃ£o e limpeza periÃ³dica                    |
| Estrutura particionada por data | Facilita buscas e filtros               | Manter consistÃªncia de nomenclatura               |
| Adiar validaÃ§Ã£o de schema       | Evita falhas por mudanÃ§as de contrato   | Monitoramento com alertas sobre mudanÃ§as crÃ­ticas |

ğŸ‡ºğŸ‡¸
# Challenge 2 â€“ Data Storage in CB LAB's Data Lake

## Objective

Store, organize, and structure the responses from 5 API endpoints related to a restaurant chain, ensuring traceability, historical consistency, and scalability for future analysis.

---

## Requested Questions

### 1. Why store API responses?

Storing API responses ensures:

- **Traceability and Auditing:** Enables future verification of inconsistencies and data validation.
- **Reliable and Historical Source:** APIs may change, go down, or be updated. Persisting data guarantees historical integrity.
- **Analysis and Reprocessing:** Allows for new analyses or report generation without re-querying the APIs.
- **Prevents Data Loss:** Ensures data persistence even if the original source fails.

---

### 2. How to store the data?

A **partitioned structure** was adopted to facilitate searches, filters, validations, and efficient reading by date and store.

```
/data-lake/raw/cb_lab_api/
â””â”€â”€ [endpoint-name]/
    â””â”€â”€ year=2025/
        â””â”€â”€ month=07/
            â””â”€â”€ day=25/
                â””â”€â”€ storeId=001/
                    â””â”€â”€ response.json
```

#### Justification:

- Clear organization by endpoint and date
- Facilitates usage by Big Data tools like Hive, Spark, or Presto
- Scalable to thousands of files
- Allows compression and retention policies

---

### 3. Schema change: `guestChecks.taxes` â†’ `guestChecks.taxation`

#### Implications:

- Breaks existing pipelines that expect the old field
- Errors in data transformation, parsing, and dashboards
- Requires schema versioning or validation

---

## Thought Process

### Steps

1. Understanding the need: raw ingestion for reprocessing and auditing
2. Creating a logical structure by date and store
3. Addressing concerns regarding volume, schema, and reliability
4. Organizing files for easy querying by analysis tools

---

## Concerns

| Type                  | Description                                                       |
|-----------------------|-------------------------------------------------------------------|
| Silent schema changes | May break pipelines â€” prepare for multiple schema versions        |
| Data volume           | Consider compression and lifecycle management                     |
| Schema validation     | Postpone to a later stage to avoid immediate failures             |

---

## Consequences of Decisions

| Decision                         | Positive Outcome                        | Potential Risk / Mitigation                        |
|----------------------------------|------------------------------------------|----------------------------------------------------|
| Storing raw JSONs                | Preserves data for reprocessing          | Use compression and periodic cleanup               |
| Partitioned structure by date    | Facilitates searches and filtering       | Maintain consistent naming conventions             |
| Delaying schema validation       | Avoids failures due to contract changes  | Monitor with alerts for critical changes           |
